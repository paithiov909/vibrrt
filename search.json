[{"path":"https://paithiov909.github.io/vibrrt/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 vibrrt authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://paithiov909.github.io/vibrrt/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Akiru Kato. Author, maintainer.","code":""},{"path":"https://paithiov909.github.io/vibrrt/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kato (2025). vibrrt: R Wrapper 'vibrato'. R package version 0.1.1, https://paithiov909.github.io/vibrrt/.","code":"@Manual{,   title = {vibrrt: An R Wrapper for 'vibrato'},   author = {Akiru Kato},   year = {2025},   note = {R package version 0.1.1},   url = {https://paithiov909.github.io/vibrrt/}, }"},{"path":"https://paithiov909.github.io/vibrrt/index.html","id":"vibrrt","dir":"","previous_headings":"","what":"An R Wrapper for vibrato","title":"An R Wrapper for vibrato","text":"R wrapper ‘vibrato’: Viterbi-based accelerated tokenizer","code":""},{"path":"https://paithiov909.github.io/vibrrt/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"An R Wrapper for vibrato","text":"install source package, Rust toolchain required.","code":"install.packages(\"vibrrt\", repos = c(\"https://paithiov909.r-universe.dev\", \"https://cloud.r-project.org\"))"},{"path":"https://paithiov909.github.io/vibrrt/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"An R Wrapper for vibrato","text":"can download model files ryan-minato/vibrato-models using hfhub package. Functions designed fashion gibasa package. Check README gibasa package detailed usage.","code":"sample_text <- jsonlite::read_json(   \"https://paithiov909.r-universe.dev/gibasa/data/ginga/json\",   simplifyVector = TRUE )  # withr::with_envvar(c(HUGGINGFACE_HUB_CACHE = tempdir()), { ipadic <- hfhub::hub_download(\"ryan-minato/vibrato-models\", \"ipadic-mecab-2_7_0/system.dic\") # })  vibrrt::tokenize(sample_text[5:8], sys_dic = ipadic) #> # A tibble: 187 × 5 #>    doc_id sentence_id token_id token        feature                              #>    <fct>        <dbl>    <dbl> <chr>        <chr>                                #>  1 1                1        1 　           記号,空白,*,*,*,*,　,　,　           #>  2 1                1        2 カムパネルラ 名詞,一般,*,*,*,*,*                  #>  3 1                1        3 が           助詞,格助詞,一般,*,*,*,が,ガ,ガ      #>  4 1                1        4 手           名詞,一般,*,*,*,*,手,テ,テ           #>  5 1                1        5 を           助詞,格助詞,一般,*,*,*,を,ヲ,ヲ      #>  6 1                1        6 あげ         動詞,自立,*,*,一段,連用形,あげる,アゲ,アゲ…… #>  7 1                1        7 まし         助動詞,*,*,*,特殊・マス,連用形,ます,マシ,マシ…… #>  8 1                1        8 た           助動詞,*,*,*,特殊・タ,基本形,た,タ,タ…… #>  9 1                1        9 。           記号,句点,*,*,*,*,。,。,。           #> 10 1                1       10 それ         名詞,代名詞,一般,*,*,*,それ,ソレ,ソレ…… #> # ℹ 177 more rows"},{"path":"https://paithiov909.github.io/vibrrt/reference/as_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a list of tokens — as_tokens","title":"Create a list of tokens — as_tokens","text":"Create list tokens","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/as_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a list of tokens — as_tokens","text":"","code":"as_tokens(   tbl,   token_field = \"token\",   pos_field = get_dict_features()[1],   nm = NULL )"},{"path":"https://paithiov909.github.io/vibrrt/reference/as_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a list of tokens — as_tokens","text":"tbl tibble tokens tokenize(). token_field <data-masked> Column containing tokens. pos_field Column containing features kept names tokens. need , give NULL argument. nm Names returned list. left NULL, \"doc_id\" field tbl used instead.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/as_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a list of tokens — as_tokens","text":"named list tokens.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":null,"dir":"Reference","previous_headings":"","what":"Bind importance of bigrams — bind_lr","title":"Bind importance of bigrams — bind_lr","text":"Calculates binds importance bigrams synergistic average.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bind importance of bigrams — bind_lr","text":"","code":"bind_lr(tbl, term = \"token\", lr_mode = c(\"n\", \"dn\"), avg_rate = 1)"},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bind importance of bigrams — bind_lr","text":"tbl tidy text dataset. term <data-masked> Column containing terms. lr_mode Method computing 'FL' 'FR' values. n equivalent 'LN' 'RN', dn equivalent 'LDN' 'RDN'. avg_rate Weight 'LR' value.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bind importance of bigrams — bind_lr","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bind importance of bigrams — bind_lr","text":"'LR' value synergistic average bigram importance based words positions (left right side).","code":""},{"path":[]},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":null,"dir":"Reference","previous_headings":"","what":"Bind term frequency and inverse document frequency — bind_tf_idf2","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"Calculates binds term frequency, inverse document frequency, TF-IDF dataset. function experimentally supports 4 types term frequencies 5 types inverse document frequencies.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"","code":"bind_tf_idf2(   tbl,   term = \"token\",   document = \"doc_id\",   n = \"n\",   tf = c(\"tf\", \"tf2\", \"tf3\", \"itf\"),   idf = c(\"idf\", \"idf2\", \"idf3\", \"idf4\", \"df\"),   norm = FALSE,   rmecab_compat = TRUE )"},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"tbl tidy text dataset. term <data-masked> Column containing terms. document <data-masked> Column containing document IDs. n <data-masked> Column containing document-term counts. tf Method computing term frequency. idf Method computing inverse document frequency. norm Logical; passed TRUE, TF-IDF values normalized divided L2 norms. rmecab_compat Logical; passed TRUE, computes values taking care compatibility 'RMeCab'. Note 'RMeCab' always computes IDF values using term frequency rather raw term counts, thus TF-IDF values may doubly affected term frequency.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"Types term frequency can switched tf argument: tf term frequency (raw count terms). tf2 logarithmic term frequency base exp(1). tf3 binary-weighted term frequency. itf inverse term frequency. Use idf=\"df\". Types inverse document frequencies can switched idf argument: idf inverse document frequency base 2, smoothed. 'smoothed' means just adding 1 raw values logarithmizing. idf2 global frequency IDF. idf3 probabilistic IDF base 2. idf4 global entropy, IDF actual. df document frequency. Use tf=\"itf\".","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse sequences of tokens by condition — collapse_tokens","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"Concatenates sequences tokens tidy text dataset, grouping expression.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"","code":"collapse_tokens(tbl, condition, .collapse = \"\")"},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"tbl tidy text dataset. condition <data-masked> logical expression. .collapse String tokens concatenated.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"Note function drops columns except 'token' columns grouping sequences. , returned data.frame 'doc_id', 'sentence_id', 'token_id', 'token' columns.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dictionary features — get_dict_features","title":"Get dictionary features — get_dict_features","text":"Returns names dictionary features. Currently supports \"unidic17\" (2.1.2 src schema), \"unidic26\" (2.1.2 bin schema), \"unidic29\" (schema used 2.2.0, 2.3.0), \"cc-cedict\", \"ko-dic\" (mecab-ko-dic), \"naist11\", \"ipa\".","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dictionary features — get_dict_features","text":"","code":"get_dict_features(   dict = c(\"ipa\", \"unidic17\", \"unidic26\", \"unidic29\", \"cc-cedict\", \"ko-dic\", \"naist11\") )"},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dictionary features — get_dict_features","text":"dict Character scalar; one \"ipa\", \"unidic17\", \"unidic26\", \"unidic29\", \"cc-cedict\", \"ko-dic\", , \"naist11\".","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dictionary features — get_dict_features","text":"character vector.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dictionary features — get_dict_features","text":"","code":"get_dict_features(\"ipa\") #> [1] \"POS1\"        \"POS2\"        \"POS3\"        \"POS4\"        \"X5StageUse1\" #> [6] \"X5StageUse2\" \"Original\"    \"Yomi1\"       \"Yomi2\""},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if scalars are blank — is_blank","title":"Check if scalars are blank — is_blank","text":"Check scalars blank","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if scalars are blank — is_blank","text":"","code":"is_blank(x, trim = TRUE, ...)"},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if scalars are blank — is_blank","text":"x Object check emptiness. trim Logical. ... Additional arguments base::sapply().","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if scalars are blank — is_blank","text":"Logicals.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if scalars are blank — is_blank","text":"","code":"is_blank(list(c(a = \"\", b = NA_character_), NULL)) #> [[1]] #> [1] TRUE TRUE #>  #> [[2]] #> [1] TRUE #>"},{"path":"https://paithiov909.github.io/vibrrt/reference/lex_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate lexical density — lex_density","title":"Calculate lexical density — lex_density","text":"lexical density proportion content words (lexical items) documents. function simple helper calculating lexical density given datasets.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/lex_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate lexical density — lex_density","text":"","code":"lex_density(vec, contents_words, targets = NULL, negate = c(FALSE, FALSE))"},{"path":"https://paithiov909.github.io/vibrrt/reference/lex_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate lexical density — lex_density","text":"vec character vector. contents_words character vector containing values counted contents words. targets character vector denominator lexical density filtered computing values. negate logical vector length 2. passed TRUE, respectively negates predicate functions counting contents words targets.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/lex_density.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate lexical density — lex_density","text":"numeric vector.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/mute_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Mute tokens by condition — mute_tokens","title":"Mute tokens by condition — mute_tokens","text":"Replaces tokens tidy text dataset string scalar matched expression.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/mute_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mute tokens by condition — mute_tokens","text":"","code":"mute_tokens(tbl, condition, .as = NA_character_)"},{"path":"https://paithiov909.github.io/vibrrt/reference/mute_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mute tokens by condition — mute_tokens","text":"tbl tidy text dataset. condition <data-masked> logical expression. .String tokens replaced matched condition. default value NA_character_.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/mute_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mute tokens by condition — mute_tokens","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Ngrams tokenizer — ngram_tokenizer","title":"Ngrams tokenizer — ngram_tokenizer","text":"Makes ngram tokenizer function.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ngrams tokenizer — ngram_tokenizer","text":"","code":"ngram_tokenizer(n = 1L)"},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ngrams tokenizer — ngram_tokenizer","text":"n Integer.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ngrams tokenizer — ngram_tokenizer","text":"ngram tokenizer function","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ngrams tokenizer — ngram_tokenizer","text":"","code":"bigram <- ngram_tokenizer(2) bigram(letters, sep = \"-\") #>  [1] \"a-b\" \"b-c\" \"c-d\" \"d-e\" \"e-f\" \"f-g\" \"g-h\" \"h-i\" \"i-j\" \"j-k\" \"k-l\" \"l-m\" #> [13] \"m-n\" \"n-o\" \"o-p\" \"p-q\" \"q-r\" \"r-s\" \"s-t\" \"t-u\" \"u-v\" \"v-w\" \"w-x\" \"x-y\" #> [25] \"y-z\""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":null,"dir":"Reference","previous_headings":"","what":"Pack a data.frame of tokens — pack","title":"Pack a data.frame of tokens — pack","text":"Packs data.frame tokens new data.frame corpus, compatible Text Interchange Formats.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pack a data.frame of tokens — pack","text":"","code":"pack(tbl, pull = \"token\", n = 1L, sep = \"-\", .collapse = \" \")"},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pack a data.frame of tokens — pack","text":"tbl data.frame tokens. pull <data-masked> Column packed text ngrams body. Default value token. n Integer internally passed ngrams tokenizer function created ngram_tokenizer() sep Character scalar internally used concatenator ngrams. .collapse argument passed stringi::stri_c().","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pack a data.frame of tokens — pack","text":"tibble.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"text-interchange-formats-tif-","dir":"Reference","previous_headings":"","what":"Text Interchange Formats (TIF)","title":"Pack a data.frame of tokens — pack","text":"Text Interchange Formats (TIF) set standards allows R text analysis packages target defined inputs outputs corpora, tokens, document-term matrices.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"valid-data-frame-of-tokens","dir":"Reference","previous_headings":"","what":"Valid data.frame of tokens","title":"Pack a data.frame of tokens — pack","text":"data.frame tokens data.frame object compatible TIF. TIF valid data.frame tokens expected one unique key column (named doc_id) text several feature columns tokens. feature columns must contain least token .","code":""},{"path":[]},{"path":"https://paithiov909.github.io/vibrrt/reference/prettify.html","id":null,"dir":"Reference","previous_headings":"","what":"Prettify tokenized output — prettify","title":"Prettify tokenized output — prettify","text":"Turns single character column features separating delimiter.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/prettify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prettify tokenized output — prettify","text":"","code":"prettify(   tbl,   col = \"feature\",   into = get_dict_features(\"ipa\"),   col_select = seq_along(into),   delim = \",\" )"},{"path":"https://paithiov909.github.io/vibrrt/reference/prettify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prettify tokenized output — prettify","text":"tbl data.frame feature column prettified. col <data-masked> Column containing features prettified. Character vector used column names features. col_select Character integer vector kept prettified features. delim Character scalar used separate fields within feature.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/prettify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prettify tokenized output — prettify","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/tokenize.html","id":null,"dir":"Reference","previous_headings":"","what":"Tokenize sentences using 'vibrato' — tokenize","title":"Tokenize sentences using 'vibrato' — tokenize","text":"Tokenize sentences using 'vibrato'","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/tokenize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tokenize sentences using 'vibrato' — tokenize","text":"","code":"tokenize(   x,   text_field = \"text\",   docid_field = \"doc_id\",   sys_dic = \"\",   user_dic = \"\",   split = FALSE,   mode = c(\"parse\", \"wakati\"),   max_grouping_len = 0L,   verbose = FALSE )"},{"path":"https://paithiov909.github.io/vibrrt/reference/tokenize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tokenize sentences using 'vibrato' — tokenize","text":"x data.frame like object character vector tokenized. text_field <data-masked> String symbol; column containing texts tokenized. docid_field <data-masked> String symbol; column containing document IDs. sys_dic Character scalar; path system dictionary 'vibrato'. user_dic Character scalar; path user dictionary 'vibrato'. split split Logical. passed TRUE, function internally splits sentences sub-sentences mode Character scalar switch output format. max_grouping_len Integer scalar; maximum grouping length unknown words. default value 0L, indicating infinity length. verbose Logical. TRUE, returns additional information debugging.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/tokenize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tokenize sentences using 'vibrato' — tokenize","text":"tibble named list tokens.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/vibrrt-package.html","id":null,"dir":"Reference","previous_headings":"","what":"vibrrt: An R Wrapper for 'vibrato' — vibrrt-package","title":"vibrrt: An R Wrapper for 'vibrato' — vibrrt-package","text":"R wrapper 'vibrato' (https://github.com/daac-tools/vibrato), Rust reimplementation 'MeCab' fast tokenization.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/vibrrt/reference/vibrrt-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"vibrrt: An R Wrapper for 'vibrato' — vibrrt-package","text":"Maintainer: Akiru Kato paithiov909@gmail.com","code":""}]
