[{"path":"https://paithiov909.github.io/vibrrt/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 vibrrt authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://paithiov909.github.io/vibrrt/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Akiru Kato. Author, maintainer.","code":""},{"path":"https://paithiov909.github.io/vibrrt/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kato (2023). vibrrt: R Wrapper 'Vibrato'. R package version 0.0.2.","code":"@Manual{,   title = {vibrrt: An R Wrapper of 'Vibrato'},   author = {Akiru Kato},   year = {2023},   note = {R package version 0.0.2}, }"},{"path":"https://paithiov909.github.io/vibrrt/index.html","id":"vibrrt","dir":"","previous_headings":"","what":"An R Wrapper of Vibrato","title":"An R Wrapper of Vibrato","text":"R wrapper ‘Vibrato’: Viterbi-based accelerated tokenizer","code":""},{"path":"https://paithiov909.github.io/vibrrt/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"An R Wrapper of Vibrato","text":"","code":"install.packages(\"vibrrt\", repos = \"https://paithiov909.r-universe.dev\")"},{"path":"https://paithiov909.github.io/vibrrt/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"An R Wrapper of Vibrato","text":"","code":"ipadic <- vibrrt::dict_path(\"ipadic-mecab-2_7_0\") if (!file.exists(ipadic)) {   vibrrt::download_dict(\"ipadic-mecab-2_7_0\") }  gibasa::ginga[5:10] |>   vibrrt::tokenize(sys_dic = ipadic) |>   vibrrt::prettify(col_select = c(\"POS1\", \"POS2\"))"},{"path":"https://paithiov909.github.io/vibrrt/index.html","id":"benchmark","dir":"","previous_headings":"","what":"Benchmark","title":"An R Wrapper of Vibrato","text":"","code":"microbenchmark::microbenchmark(   gibasa = gibasa::tokenize(gibasa::ginga, mode = \"wakati\"),   vibrrt_ipadic = vibrrt::tokenize(     gibasa::ginga,     sys_dic = vibrrt::dict_path(\"ipadic-mecab-2_7_0\"),     mode = \"wakati\"   ),   times = 10L,   check = \"equal\" ) #> Unit: milliseconds #>           expr      min       lq     mean   median       uq      max neval #>         gibasa 104.3151 107.1517 113.6609 108.2799 116.5667 151.5655    10 #>  vibrrt_ipadic 400.1805 406.0459 437.5194 423.5166 456.0265 521.1660    10 microbenchmark::microbenchmark(   gibasa = gibasa::tokenize(     gibasa::ginga,     sys_dic = \"/usr/local/lib/python3.10/dist-packages/unidic_lite/dicdir\",     mode = \"wakati\"   ),   vibrrt_unidic = vibrrt::tokenize(     gibasa::ginga,     sys_dic = vibrrt::dict_path(\"unidic-mecab-2_1_2\"),     mode = \"wakati\"   ),   times = 5L ) #> Unit: milliseconds #>           expr       min       lq     mean   median        uq      max neval #>         gibasa  386.1541  390.373 1158.620  544.906  630.9402 3840.727     5 #>  vibrrt_unidic 2334.7467 2352.088 2628.865 2404.555 2474.3871 3578.548     5"},{"path":"https://paithiov909.github.io/vibrrt/reference/as_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a list of tokens — as_tokens","title":"Create a list of tokens — as_tokens","text":"Create list tokens","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/as_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a list of tokens — as_tokens","text":"","code":"as_tokens(   tbl,   token_field = \"token\",   pos_field = get_dict_features()[1],   nm = NULL )"},{"path":"https://paithiov909.github.io/vibrrt/reference/as_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a list of tokens — as_tokens","text":"tbl tibble tokens vibrrt::tokenize(). token_field <[`data-masked`][rlang::args_data_masking]> Column name contains tokens. pos_field Feature name kept names tokens. need , give `NULL` argument. nm Names returned list. left `NULL`, \"doc_id\" field `tbl` used instead.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/as_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a list of tokens — as_tokens","text":"named list tokens.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":null,"dir":"Reference","previous_headings":"","what":"Bind importance of bigrams — bind_lr","title":"Bind importance of bigrams — bind_lr","text":"Calculates binds importance bigrams synergistic average.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bind importance of bigrams — bind_lr","text":"","code":"bind_lr(tbl, term = \"token\", lr_mode = c(\"n\", \"dn\"), avg_rate = 1)"},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bind importance of bigrams — bind_lr","text":"tbl tidy text dataset. term <[`data-masked`][rlang::args_data_masking]> Column containing terms string symbol. lr_mode Method computing 'FL' 'FR' values. `n` equivalent 'LN' 'RN', `dn` equivalent 'LDN' 'RDN'. avg_rate Weight 'LR' value.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bind importance of bigrams — bind_lr","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bind importance of bigrams — bind_lr","text":"'LR' value synergistic average bigram importance based words positions (left right side).","code":""},{"path":[]},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_lr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bind importance of bigrams — bind_lr","text":"","code":"if (FALSE) { df <- tokenize(   data.frame(     doc_id = seq_along(ginga[5:8]),     text = ginga[5:8]   ) ) bind_lr(df) }"},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":null,"dir":"Reference","previous_headings":"","what":"Bind term frequency and inverse document frequency — bind_tf_idf2","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"Calculates binds term frequency, inverse document frequency, TF-IDF dataset. function experimentally supports 3 types term frequencies 4 types inverse document frequencies, implemented 'RMeCab' package.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"","code":"bind_tf_idf2(   tbl,   term = \"token\",   document = \"doc_id\",   n = \"n\",   tf = c(\"tf\", \"tf2\", \"tf3\"),   idf = c(\"idf\", \"idf2\", \"idf3\", \"idf4\"),   norm = FALSE,   rmecab_compat = TRUE )"},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"tbl tidy text dataset. term <[`data-masked`][rlang::args_data_masking]> Column containing terms string symbol. document <[`data-masked`][rlang::args_data_masking]> Column containing document IDs string symbol. n <[`data-masked`][rlang::args_data_masking]> Column containing document-term counts string symbol. tf Method computing term frequency. idf Method computing inverse document frequency. norm Logical; passed `TRUE`, raw term counts normalized divided L2 norms computing IDF values. rmecab_compat Logical; passed `TRUE`, computes values taking care compatibility 'RMeCab'. Note 'RMeCab' always computes IDF values using term frequency rather raw term counts, thus TF-IDF values may doubly affected term frequency.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/bind_tf_idf2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bind term frequency and inverse document frequency — bind_tf_idf2","text":"Types term frequency can switched `tf` argument: * `tf` term frequency (raw count terms). * `tf2` logarithmic term frequency base `exp(1)`. * `tf3` binary-weighted term frequency. Types inverse document frequencies can switched `idf` argument: * `idf` inverse document frequency base 2, smoothed. 'smoothed' means just adding 1 raw counts logarithmizing. * `idf2` global frequency IDF. * `idf3` probabilistic IDF base 2. * `idf4` global entropy, IDF actual.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse sequences of tokens by condition — collapse_tokens","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"Concatenates sequences tokens tidy text dataset, grouping expression.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"","code":"collapse_tokens(tbl, condition, .collapse = \"\")"},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"tbl tidy text dataset. condition <[`data-masked`][rlang::args_data_masking]> logical expression. .collapse String tokens concatenated.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/collapse_tokens.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Collapse sequences of tokens by condition — collapse_tokens","text":"Note function drops columns except 'token' columns grouping sequences. , returned data.frame 'doc_id', 'sentence_id', 'token_id', 'token' columns.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/dict_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the path to a dictionary file — dict_path","title":"Get the path to a dictionary file — dict_path","text":"Get path dictionary file","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/dict_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the path to a dictionary file — dict_path","text":"","code":"dict_path(   dict = c(\"ipadic-mecab-2_7_0\", \"jumandic-mecab-7_0\", \"naist-jdic-mecab-0_6_3b\",     \"unidic-mecab-2_1_2\", \"unidic-cwj-3_1_1+compact-dual\"),   dict_dir = NULL )"},{"path":"https://paithiov909.github.io/vibrrt/reference/dict_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the path to a dictionary file — dict_path","text":"dict Dictionary name. dict_dir Directory dictionaries placed. default, return value rappdirs::user_cache_dir(\"vibrrt\") used.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/download_dict.html","id":null,"dir":"Reference","previous_headings":"","what":"Download dictionary file — download_dict","title":"Download dictionary file — download_dict","text":"Download dictionary file","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/download_dict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download dictionary file — download_dict","text":"","code":"download_dict(   dict = c(\"ipadic-mecab-2_7_0\", \"jumandic-mecab-7_0\", \"naist-jdic-mecab-0_6_3b\",     \"unidic-mecab-2_1_2\", \"unidic-cwj-3_1_1+compact-dual\"),   dict_dir = NULL )"},{"path":"https://paithiov909.github.io/vibrrt/reference/download_dict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download dictionary file — download_dict","text":"dict Dictionary name. dict_dir Directory dictionaries placed. default, return value rappdirs::user_cache_dir(\"vibrrt\") used.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/download_dict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download dictionary file — download_dict","text":"path 'system.dic' file returned invisibly.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dictionary's features — get_dict_features","title":"Get dictionary's features — get_dict_features","text":"Returns dictionary's features. Currently supports \"unidic17\" (2.1.2 src schema), \"unidic26\" (2.1.2 bin schema), \"unidic29\" (schema used 2.2.0, 2.3.0), \"cc-cedict\", \"ko-dic\" (mecab-ko-dic), \"naist11\", \"sudachi\", \"ipa\".","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dictionary's features — get_dict_features","text":"","code":"get_dict_features(   dict = c(\"ipa\", \"unidic17\", \"unidic26\", \"unidic29\", \"cc-cedict\", \"ko-dic\", \"naist11\",     \"sudachi\") )"},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dictionary's features — get_dict_features","text":"dict Character scalar; one \"ipa\", \"unidic17\", \"unidic26\", \"unidic29\", \"cc-cedict\", \"ko-dic\", \"naist11\", \"sudachi\".","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dictionary's features — get_dict_features","text":"character vector.","code":""},{"path":[]},{"path":"https://paithiov909.github.io/vibrrt/reference/get_dict_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dictionary's features — get_dict_features","text":"","code":"get_dict_features(\"ipa\") #> [1] \"POS1\"        \"POS2\"        \"POS3\"        \"POS4\"        \"X5StageUse1\" #> [6] \"X5StageUse2\" \"Original\"    \"Yomi1\"       \"Yomi2\""},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if scalars are blank — is_blank","title":"Check if scalars are blank — is_blank","text":"Check scalars blank","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if scalars are blank — is_blank","text":"","code":"is_blank(x, trim = TRUE, ...)"},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if scalars are blank — is_blank","text":"x Object check emptiness. trim Logical. ... Additional arguments base::sapply().","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if scalars are blank — is_blank","text":"Logical.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/is_blank.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if scalars are blank — is_blank","text":"","code":"is_blank(list(c(a = \"\", b = NA_character_), NULL)) #> [[1]] #> [1] TRUE TRUE #>  #> [[2]] #> [1] TRUE #>"},{"path":"https://paithiov909.github.io/vibrrt/reference/lex_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate lexical density — lex_density","title":"Calculate lexical density — lex_density","text":"lexical density proportion content words (lexical items) documents. function simple helper calculating lexical density given datasets.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/lex_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate lexical density — lex_density","text":"","code":"lex_density(vec, contents_words, targets = NULL, negate = c(FALSE, FALSE))"},{"path":"https://paithiov909.github.io/vibrrt/reference/lex_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate lexical density — lex_density","text":"vec character vector. contents_words character vector containing values counted contents words. targets character vector denominator lexical density filtered computing values. negate logical vector length 2. passed `TRUE`, respectively negates predicate functions counting contents words targets.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/lex_density.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate lexical density — lex_density","text":"numeric vector.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/mute_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Mute tokens by condition — mute_tokens","title":"Mute tokens by condition — mute_tokens","text":"Permutes tokens tidy text dataset string scalar matched expression.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/mute_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mute tokens by condition — mute_tokens","text":"","code":"mute_tokens(tbl, condition, .as = NA_character_)"},{"path":"https://paithiov909.github.io/vibrrt/reference/mute_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mute tokens by condition — mute_tokens","text":"tbl tidy text dataset. condition <[`data-masked`][rlang::args_data_masking]> logical expression. .String tokens replaced matched condition. default value `NA_character`.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/mute_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mute tokens by condition — mute_tokens","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Ngrams tokenizer — ngram_tokenizer","title":"Ngrams tokenizer — ngram_tokenizer","text":"Make ngram tokenizer function.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ngrams tokenizer — ngram_tokenizer","text":"","code":"ngram_tokenizer(n = 1L)"},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ngrams tokenizer — ngram_tokenizer","text":"n Integer.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ngrams tokenizer — ngram_tokenizer","text":"ngram tokenizer function","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/ngram_tokenizer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ngrams tokenizer — ngram_tokenizer","text":"","code":"bigram <- ngram_tokenizer(2) bigram(letters, sep = \"-\") #>  [1] \"a-b\" \"b-c\" \"c-d\" \"d-e\" \"e-f\" \"f-g\" \"g-h\" \"h-i\" \"i-j\" \"j-k\" \"k-l\" \"l-m\" #> [13] \"m-n\" \"n-o\" \"o-p\" \"p-q\" \"q-r\" \"r-s\" \"s-t\" \"t-u\" \"u-v\" \"v-w\" \"w-x\" \"x-y\" #> [25] \"y-z\""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":null,"dir":"Reference","previous_headings":"","what":"Pack a data.frame of tokens — pack","title":"Pack a data.frame of tokens — pack","text":"Packs data.frame tokens new data.frame corpus, compatible Text Interchange Formats.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pack a data.frame of tokens — pack","text":"","code":"pack(tbl, pull = \"token\", n = 1L, sep = \"-\", .collapse = \" \")"},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pack a data.frame of tokens — pack","text":"tbl data.frame tokens. pull <[`data-masked`][rlang::args_data_masking]> Column packed text ngrams body. Default value `token`. n Integer internally passed ngrams tokenizer function created vibrrt::ngram_tokenizer() sep Character scalar internally used concatenator ngrams. .collapse argument passed stringi::stri_c().","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pack a data.frame of tokens — pack","text":"tibble.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"text-interchange-formats-tif-","dir":"Reference","previous_headings":"","what":"Text Interchange Formats (TIF)","title":"Pack a data.frame of tokens — pack","text":"Text Interchange Formats (TIF) set standards allows R text analysis packages target defined inputs outputs corpora, tokens, document-term matrices.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/pack.html","id":"valid-data-frame-of-tokens","dir":"Reference","previous_headings":"","what":"Valid data.frame of tokens","title":"Pack a data.frame of tokens — pack","text":"data.frame tokens data.frame object compatible TIF. TIF valid data.frame tokens expected one unique key column (named `doc_id`) text several feature columns tokens. feature columns must contain least `token` .","code":""},{"path":[]},{"path":"https://paithiov909.github.io/vibrrt/reference/prettify.html","id":null,"dir":"Reference","previous_headings":"","what":"Prettify tokenized output — prettify","title":"Prettify tokenized output — prettify","text":"Turns single character column features separating delimiter.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/prettify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prettify tokenized output — prettify","text":"","code":"prettify(   tbl,   col = \"feature\",   into = get_dict_features(\"ipa\"),   col_select = seq_along(into),   delim = \",\" )"},{"path":"https://paithiov909.github.io/vibrrt/reference/prettify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prettify tokenized output — prettify","text":"tbl data.frame feature column prettified. col <[`data-masked`][rlang::args_data_masking]> Column name prettified. Character vector used column names features. col_select Character integer vector kept prettified features. delim Character scalar used separate fields within feature.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/prettify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prettify tokenized output — prettify","text":"data.frame.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/prettify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prettify tokenized output — prettify","text":"","code":"prettify(   data.frame(x = c(\"x,y\", \"y,z\", \"z,x\")),   col = \"x\",   into = c(\"a\", \"b\"),   col_select = \"b\" ) #>   b #> 1 y #> 2 z #> 3 x"},{"path":"https://paithiov909.github.io/vibrrt/reference/tokenize.html","id":null,"dir":"Reference","previous_headings":"","what":"Tokenize sentences using 'Vibrato' — tokenize","title":"Tokenize sentences using 'Vibrato' — tokenize","text":"Tokenize sentences using 'Vibrato'","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/tokenize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tokenize sentences using 'Vibrato' — tokenize","text":"","code":"tokenize(   x,   text_field = \"text\",   docid_field = \"doc_id\",   sys_dic = \"\",   user_dic = \"\",   split = FALSE,   mode = c(\"parse\", \"wakati\") )"},{"path":"https://paithiov909.github.io/vibrrt/reference/tokenize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tokenize sentences using 'Vibrato' — tokenize","text":"x data.frame like object character vector tokenized. text_field String symbol; column name get texts tokenized. docid_field String symbol; column name get identifiers texts. sys_dic Character scalar; path system dictionary 'Vibrato'. user_dic Character scalar; path user dictionary 'Vibrato'. split Logical. passed `TRUE`, function internally splits sentence sub-sentences using stringi::stri_split_boundaries(type = \"sentence\"). mode Character scalar switch output format.","code":""},{"path":"https://paithiov909.github.io/vibrrt/reference/tokenize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tokenize sentences using 'Vibrato' — tokenize","text":"tibble named list tokens.","code":""}]
